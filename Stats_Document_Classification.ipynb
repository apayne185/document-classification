{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIGTQuvp67YI",
        "outputId": "59efc32d-ed35-40e3-ae38-7fbf6c58d1e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.4.1)\n",
            "Requirement already satisfied: kaggle in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.6.17)\n",
            "Requirement already satisfied: PyMuPDF in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.24.1)\n",
            "Requirement already satisfied: Pillow in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (10.1.0)\n",
            "Collecting tf-keras\n",
            "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tesseract-ocr\n",
            "  Using cached tesseract-ocr-0.0.1.tar.gz (33 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: filelock in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.2.0)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.29.2)\n",
            "Requirement already satisfied: packaging in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: six>=1.10 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: python-slugify in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (1.26.18)\n",
            "Requirement already satisfied: bleach in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kaggle) (5.0.1)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from PyMuPDF) (1.24.1)\n",
            "Collecting tensorflow<2.20,>=2.19 (from tf-keras)\n",
            "  Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
            "Collecting cython (from tesseract-ocr)\n",
            "  Using cached Cython-3.0.12-cp312-cp312-win_amd64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (16.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (5.29.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (76.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (1.70.0)\n",
            "Collecting tensorboard~=2.19.0 (from tensorflow<2.20,>=2.19->tf-keras)\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras) (3.6.0)\n",
            "Collecting h5py>=3.11.0 (from tensorflow<2.20,>=2.19->tf-keras)\n",
            "  Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
            "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow<2.20,>=2.19->tf-keras)\n",
            "  Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: colorama in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: webencodings in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras) (0.40.0)\n",
            "Requirement already satisfied: rich in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (13.6.0)\n",
            "Requirement already satisfied: namex in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.0.7)\n",
            "Requirement already satisfied: optree in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.13.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (2.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras) (2.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras) (0.1.2)\n",
            "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
            "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.7/1.7 MB 9.4 MB/s eta 0:00:00\n",
            "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
            "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
            "   ---------------------------------------- 1.6/376.0 MB 7.6 MB/s eta 0:00:50\n",
            "   ---------------------------------------- 3.7/376.0 MB 8.4 MB/s eta 0:00:45\n",
            "    --------------------------------------- 6.0/376.0 MB 9.7 MB/s eta 0:00:39\n",
            "    --------------------------------------- 8.7/376.0 MB 10.5 MB/s eta 0:00:35\n",
            "   - -------------------------------------- 10.5/376.0 MB 10.2 MB/s eta 0:00:36\n",
            "   - -------------------------------------- 13.4/376.0 MB 10.6 MB/s eta 0:00:35\n",
            "   - -------------------------------------- 16.3/376.0 MB 11.1 MB/s eta 0:00:33\n",
            "   -- ------------------------------------- 19.1/376.0 MB 11.4 MB/s eta 0:00:32\n",
            "   -- ------------------------------------- 21.5/376.0 MB 11.5 MB/s eta 0:00:31\n",
            "   -- ------------------------------------- 24.1/376.0 MB 11.7 MB/s eta 0:00:30\n",
            "   -- ------------------------------------- 27.0/376.0 MB 11.8 MB/s eta 0:00:30\n",
            "   --- ------------------------------------ 30.1/376.0 MB 12.0 MB/s eta 0:00:29\n",
            "   --- ------------------------------------ 32.8/376.0 MB 12.1 MB/s eta 0:00:29\n",
            "   --- ------------------------------------ 35.7/376.0 MB 12.2 MB/s eta 0:00:28\n",
            "   ---- ----------------------------------- 38.5/376.0 MB 12.3 MB/s eta 0:00:28\n",
            "   ---- ----------------------------------- 40.9/376.0 MB 12.3 MB/s eta 0:00:28\n",
            "   ---- ----------------------------------- 43.8/376.0 MB 12.4 MB/s eta 0:00:27\n",
            "   ---- ----------------------------------- 46.4/376.0 MB 12.4 MB/s eta 0:00:27\n",
            "   ----- ---------------------------------- 49.0/376.0 MB 12.4 MB/s eta 0:00:27\n",
            "   ----- ---------------------------------- 51.6/376.0 MB 12.3 MB/s eta 0:00:27\n",
            "   ----- ---------------------------------- 53.7/376.0 MB 12.2 MB/s eta 0:00:27\n",
            "   ----- ---------------------------------- 55.6/376.0 MB 12.0 MB/s eta 0:00:27\n",
            "   ------ --------------------------------- 57.4/376.0 MB 11.9 MB/s eta 0:00:27\n",
            "   ------ --------------------------------- 59.2/376.0 MB 11.8 MB/s eta 0:00:27\n",
            "   ------ --------------------------------- 61.9/376.0 MB 11.8 MB/s eta 0:00:27\n",
            "   ------ --------------------------------- 64.5/376.0 MB 11.8 MB/s eta 0:00:27\n",
            "   ------- -------------------------------- 66.8/376.0 MB 11.7 MB/s eta 0:00:27\n",
            "   ------- -------------------------------- 69.2/376.0 MB 11.7 MB/s eta 0:00:27\n",
            "   ------- -------------------------------- 71.6/376.0 MB 11.7 MB/s eta 0:00:27\n",
            "   ------- -------------------------------- 73.7/376.0 MB 11.7 MB/s eta 0:00:26\n",
            "   -------- ------------------------------- 76.3/376.0 MB 11.7 MB/s eta 0:00:26\n",
            "   -------- ------------------------------- 78.6/376.0 MB 11.7 MB/s eta 0:00:26\n",
            "   -------- ------------------------------- 80.7/376.0 MB 11.6 MB/s eta 0:00:26\n",
            "   -------- ------------------------------- 82.8/376.0 MB 11.6 MB/s eta 0:00:26\n",
            "   --------- ------------------------------ 86.0/376.0 MB 11.7 MB/s eta 0:00:25\n",
            "   --------- ------------------------------ 88.9/376.0 MB 11.7 MB/s eta 0:00:25\n",
            "   --------- ------------------------------ 90.7/376.0 MB 11.6 MB/s eta 0:00:25\n",
            "   --------- ------------------------------ 93.1/376.0 MB 11.6 MB/s eta 0:00:25\n",
            "   ---------- ----------------------------- 95.4/376.0 MB 11.6 MB/s eta 0:00:25\n",
            "   ---------- ----------------------------- 98.0/376.0 MB 11.6 MB/s eta 0:00:24\n",
            "   ---------- ---------------------------- 100.4/376.0 MB 11.6 MB/s eta 0:00:24\n",
            "   ---------- ---------------------------- 102.8/376.0 MB 11.6 MB/s eta 0:00:24\n",
            "   ---------- ---------------------------- 105.1/376.0 MB 11.6 MB/s eta 0:00:24\n",
            "   ----------- --------------------------- 107.5/376.0 MB 11.6 MB/s eta 0:00:24\n",
            "   ----------- --------------------------- 109.6/376.0 MB 11.5 MB/s eta 0:00:24\n",
            "   ----------- --------------------------- 111.1/376.0 MB 11.5 MB/s eta 0:00:24\n",
            "   ----------- --------------------------- 113.5/376.0 MB 11.4 MB/s eta 0:00:23\n",
            "   ------------ -------------------------- 116.1/376.0 MB 11.4 MB/s eta 0:00:23\n",
            "   ------------ -------------------------- 119.0/376.0 MB 11.5 MB/s eta 0:00:23\n",
            "   ------------ -------------------------- 121.4/376.0 MB 11.4 MB/s eta 0:00:23\n",
            "   ------------ -------------------------- 122.9/376.0 MB 11.4 MB/s eta 0:00:23\n",
            "   ------------ -------------------------- 124.8/376.0 MB 11.3 MB/s eta 0:00:23\n",
            "   ------------- ------------------------- 127.1/376.0 MB 11.3 MB/s eta 0:00:22\n",
            "   ------------- ------------------------- 129.2/376.0 MB 11.3 MB/s eta 0:00:22\n",
            "   ------------- ------------------------- 131.6/376.0 MB 11.3 MB/s eta 0:00:22\n",
            "   ------------- ------------------------- 134.5/376.0 MB 11.3 MB/s eta 0:00:22\n",
            "   -------------- ------------------------ 137.4/376.0 MB 11.4 MB/s eta 0:00:22\n",
            "   -------------- ------------------------ 140.0/376.0 MB 11.4 MB/s eta 0:00:21\n",
            "   -------------- ------------------------ 142.6/376.0 MB 11.4 MB/s eta 0:00:21\n",
            "   --------------- ----------------------- 145.2/376.0 MB 11.4 MB/s eta 0:00:21\n",
            "   --------------- ----------------------- 148.1/376.0 MB 11.5 MB/s eta 0:00:20\n",
            "   --------------- ----------------------- 151.3/376.0 MB 11.5 MB/s eta 0:00:20\n",
            "   --------------- ----------------------- 153.9/376.0 MB 11.5 MB/s eta 0:00:20\n",
            "   ---------------- ---------------------- 156.8/376.0 MB 11.5 MB/s eta 0:00:19\n",
            "   ---------------- ---------------------- 159.4/376.0 MB 11.6 MB/s eta 0:00:19\n",
            "   ---------------- ---------------------- 162.0/376.0 MB 11.6 MB/s eta 0:00:19\n",
            "   ----------------- --------------------- 164.4/376.0 MB 11.6 MB/s eta 0:00:19\n",
            "   ----------------- --------------------- 166.7/376.0 MB 11.6 MB/s eta 0:00:19\n",
            "   ----------------- --------------------- 169.1/376.0 MB 11.5 MB/s eta 0:00:18\n",
            "   ----------------- --------------------- 171.7/376.0 MB 11.6 MB/s eta 0:00:18\n",
            "   ------------------ -------------------- 174.3/376.0 MB 11.6 MB/s eta 0:00:18\n",
            "   ------------------ -------------------- 176.9/376.0 MB 11.6 MB/s eta 0:00:18\n",
            "   ------------------ -------------------- 179.8/376.0 MB 11.6 MB/s eta 0:00:17\n",
            "   ------------------ -------------------- 182.2/376.0 MB 11.6 MB/s eta 0:00:17\n",
            "   ------------------- ------------------- 184.8/376.0 MB 11.6 MB/s eta 0:00:17\n",
            "   ------------------- ------------------- 187.4/376.0 MB 11.6 MB/s eta 0:00:17\n",
            "   ------------------- ------------------- 190.1/376.0 MB 11.7 MB/s eta 0:00:16\n",
            "   -------------------- ------------------ 193.2/376.0 MB 11.7 MB/s eta 0:00:16\n",
            "   -------------------- ------------------ 195.8/376.0 MB 11.7 MB/s eta 0:00:16\n",
            "   -------------------- ------------------ 199.0/376.0 MB 11.7 MB/s eta 0:00:16\n",
            "   -------------------- ------------------ 201.9/376.0 MB 11.8 MB/s eta 0:00:15\n",
            "   --------------------- ----------------- 204.7/376.0 MB 11.8 MB/s eta 0:00:15\n",
            "   --------------------- ----------------- 207.4/376.0 MB 11.8 MB/s eta 0:00:15\n",
            "   --------------------- ----------------- 209.5/376.0 MB 11.8 MB/s eta 0:00:15\n",
            "   --------------------- ----------------- 211.8/376.0 MB 11.8 MB/s eta 0:00:14\n",
            "   ---------------------- ---------------- 214.4/376.0 MB 11.8 MB/s eta 0:00:14\n",
            "   ---------------------- ---------------- 216.5/376.0 MB 11.7 MB/s eta 0:00:14\n",
            "   ---------------------- ---------------- 219.4/376.0 MB 11.8 MB/s eta 0:00:14\n",
            "   ----------------------- --------------- 222.0/376.0 MB 11.8 MB/s eta 0:00:14\n",
            "   ----------------------- --------------- 224.1/376.0 MB 11.8 MB/s eta 0:00:13\n",
            "   ----------------------- --------------- 226.2/376.0 MB 11.7 MB/s eta 0:00:13\n",
            "   ----------------------- --------------- 227.8/376.0 MB 11.7 MB/s eta 0:00:13\n",
            "   ----------------------- --------------- 230.7/376.0 MB 11.7 MB/s eta 0:00:13\n",
            "   ------------------------ -------------- 232.8/376.0 MB 11.7 MB/s eta 0:00:13\n",
            "   ------------------------ -------------- 235.4/376.0 MB 11.7 MB/s eta 0:00:13\n",
            "   ------------------------ -------------- 238.3/376.0 MB 11.7 MB/s eta 0:00:12\n",
            "   ------------------------ -------------- 240.6/376.0 MB 11.7 MB/s eta 0:00:12\n",
            "   ------------------------- ------------- 243.0/376.0 MB 11.7 MB/s eta 0:00:12\n",
            "   ------------------------- ------------- 245.4/376.0 MB 11.7 MB/s eta 0:00:12\n",
            "   ------------------------- ------------- 248.0/376.0 MB 11.7 MB/s eta 0:00:11\n",
            "   ------------------------- ------------- 250.6/376.0 MB 11.7 MB/s eta 0:00:11\n",
            "   -------------------------- ------------ 253.2/376.0 MB 11.7 MB/s eta 0:00:11\n",
            "   -------------------------- ------------ 256.1/376.0 MB 11.7 MB/s eta 0:00:11\n",
            "   -------------------------- ------------ 258.5/376.0 MB 11.7 MB/s eta 0:00:11\n",
            "   --------------------------- ----------- 260.3/376.0 MB 11.7 MB/s eta 0:00:10\n",
            "   --------------------------- ----------- 261.9/376.0 MB 11.7 MB/s eta 0:00:10\n",
            "   --------------------------- ----------- 262.9/376.0 MB 11.6 MB/s eta 0:00:10\n",
            "   --------------------------- ----------- 265.0/376.0 MB 11.6 MB/s eta 0:00:10\n",
            "   --------------------------- ----------- 266.6/376.0 MB 11.6 MB/s eta 0:00:10\n",
            "   --------------------------- ----------- 269.2/376.0 MB 11.6 MB/s eta 0:00:10\n",
            "   ---------------------------- ---------- 271.8/376.0 MB 11.6 MB/s eta 0:00:09\n",
            "   ---------------------------- ---------- 274.7/376.0 MB 11.6 MB/s eta 0:00:09\n",
            "   ---------------------------- ---------- 277.6/376.0 MB 11.6 MB/s eta 0:00:09\n",
            "   ----------------------------- --------- 280.2/376.0 MB 11.6 MB/s eta 0:00:09\n",
            "   ----------------------------- --------- 283.1/376.0 MB 11.6 MB/s eta 0:00:08\n",
            "   ----------------------------- --------- 285.7/376.0 MB 11.6 MB/s eta 0:00:08\n",
            "   ----------------------------- --------- 288.1/376.0 MB 11.6 MB/s eta 0:00:08\n",
            "   ------------------------------ -------- 290.7/376.0 MB 11.6 MB/s eta 0:00:08\n",
            "   ------------------------------ -------- 293.6/376.0 MB 11.6 MB/s eta 0:00:08\n",
            "   ------------------------------ -------- 295.7/376.0 MB 11.6 MB/s eta 0:00:07\n",
            "   ------------------------------ -------- 298.1/376.0 MB 11.5 MB/s eta 0:00:07\n",
            "   ------------------------------- ------- 300.7/376.0 MB 11.5 MB/s eta 0:00:07\n",
            "   ------------------------------- ------- 303.0/376.0 MB 11.5 MB/s eta 0:00:07\n",
            "   ------------------------------- ------- 305.1/376.0 MB 11.5 MB/s eta 0:00:07\n",
            "   ------------------------------- ------- 307.5/376.0 MB 11.5 MB/s eta 0:00:06\n",
            "   -------------------------------- ------ 310.4/376.0 MB 11.5 MB/s eta 0:00:06\n",
            "   -------------------------------- ------ 312.5/376.0 MB 11.4 MB/s eta 0:00:06\n",
            "   -------------------------------- ------ 314.6/376.0 MB 11.4 MB/s eta 0:00:06\n",
            "   -------------------------------- ------ 317.5/376.0 MB 11.5 MB/s eta 0:00:06\n",
            "   --------------------------------- ----- 320.3/376.0 MB 11.6 MB/s eta 0:00:05\n",
            "   --------------------------------- ----- 322.7/376.0 MB 11.6 MB/s eta 0:00:05\n",
            "   --------------------------------- ----- 325.6/376.0 MB 11.6 MB/s eta 0:00:05\n",
            "   --------------------------------- ----- 327.7/376.0 MB 11.6 MB/s eta 0:00:05\n",
            "   ---------------------------------- ---- 330.3/376.0 MB 11.6 MB/s eta 0:00:04\n",
            "   ---------------------------------- ---- 332.7/376.0 MB 11.6 MB/s eta 0:00:04\n",
            "   ---------------------------------- ---- 335.3/376.0 MB 11.6 MB/s eta 0:00:04\n",
            "   ----------------------------------- --- 338.2/376.0 MB 11.6 MB/s eta 0:00:04\n",
            "   ----------------------------------- --- 340.0/376.0 MB 11.6 MB/s eta 0:00:04\n",
            "   ----------------------------------- --- 343.4/376.0 MB 11.6 MB/s eta 0:00:03\n",
            "   ----------------------------------- --- 346.0/376.0 MB 11.7 MB/s eta 0:00:03\n",
            "   ------------------------------------ -- 348.1/376.0 MB 11.6 MB/s eta 0:00:03\n",
            "   ------------------------------------ -- 350.7/376.0 MB 11.6 MB/s eta 0:00:03\n",
            "   ------------------------------------ -- 353.6/376.0 MB 11.7 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 356.8/376.0 MB 11.7 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 359.9/376.0 MB 11.7 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 362.5/376.0 MB 11.7 MB/s eta 0:00:02\n",
            "   ------------------------------------- - 365.4/376.0 MB 11.8 MB/s eta 0:00:01\n",
            "   --------------------------------------  366.7/376.0 MB 11.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  369.6/376.0 MB 11.7 MB/s eta 0:00:01\n",
            "   --------------------------------------  372.8/376.0 MB 11.8 MB/s eta 0:00:01\n",
            "   --------------------------------------  375.4/376.0 MB 11.8 MB/s eta 0:00:01\n",
            "   --------------------------------------  375.9/376.0 MB 11.8 MB/s eta 0:00:01\n",
            "   --------------------------------------  375.9/376.0 MB 11.8 MB/s eta 0:00:01\n",
            "   --------------------------------------  375.9/376.0 MB 11.8 MB/s eta 0:00:01\n",
            "   --------------------------------------  375.9/376.0 MB 11.8 MB/s eta 0:00:01\n",
            "   --------------------------------------- 376.0/376.0 MB 11.3 MB/s eta 0:00:00\n",
            "Using cached Cython-3.0.12-cp312-cp312-win_amd64.whl (2.8 MB)\n",
            "Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl (3.0 MB)\n",
            "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
            "   ---------------------------------------  2.9/3.0 MB 14.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 3.0/3.0 MB 12.3 MB/s eta 0:00:00\n",
            "Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
            "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
            "   ----------------- ---------------------- 2.4/5.5 MB 12.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 5.0/5.5 MB 11.6 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 5.5/5.5 MB 10.5 MB/s eta 0:00:00\n",
            "Building wheels for collected packages: tesseract-ocr\n",
            "  Building wheel for tesseract-ocr (setup.py): started\n",
            "  Building wheel for tesseract-ocr (setup.py): finished with status 'error'\n",
            "  Running setup.py clean for tesseract-ocr\n",
            "Failed to build tesseract-ocr\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  error: subprocess-exited-with-error\n",
            "  \n",
            "  × python setup.py bdist_wheel did not run successfully.\n",
            "  │ exit code: 1\n",
            "  ╰─> [29 lines of output]\n",
            "      c:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\dist.py:493: SetuptoolsDeprecationWarning: Invalid dash-separated options\n",
            "      !!\n",
            "      \n",
            "              ********************************************************************************\n",
            "              Usage of dash-separated 'description-file' will not be supported in future\n",
            "              versions. Please use the underscore name 'description_file' instead.\n",
            "      \n",
            "              This deprecation is overdue, please update your project and remove deprecated\n",
            "              calls to avoid build errors in the future.\n",
            "      \n",
            "              See https://setuptools.pypa.io/en/latest/userguide/declarative_config.html for details.\n",
            "              ********************************************************************************\n",
            "      \n",
            "      !!\n",
            "        opt = self.warn_dash_deprecation(opt, section)\n",
            "      c:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:289: UserWarning: Unknown distribution option: 'tests_require'\n",
            "        warnings.warn(msg)\n",
            "      running bdist_wheel\n",
            "      running build\n",
            "      running build_py\n",
            "      file tesseract_ocr.py (for module tesseract_ocr) not found\n",
            "      file tesseract_ocr.py (for module tesseract_ocr) not found\n",
            "      running build_ext\n",
            "      building 'tesseract_ocr' extension\n",
            "      creating build\\temp.win-amd64-cpython-312\\Release\n",
            "      \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.37.32822\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -Ic:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\include -Ic:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Include \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Tools\\MSVC\\14.37.32822\\include\" \"-IC:\\Program Files (x86)\\Microsoft Visual Studio\\2022\\BuildTools\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /EHsc /Tptesseract_ocr.cpp /Fobuild\\temp.win-amd64-cpython-312\\Release\\tesseract_ocr.obj\n",
            "      tesseract_ocr.cpp\n",
            "      tesseract_ocr.cpp(264): fatal error C1083: Cannot open include file: 'leptonica/allheaders.h': No such file or directory\n",
            "      error: command 'C:\\\\Program Files (x86)\\\\Microsoft Visual Studio\\\\2022\\\\BuildTools\\\\VC\\\\Tools\\\\MSVC\\\\14.37.32822\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
            "      [end of output]\n",
            "  \n",
            "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  ERROR: Failed building wheel for tesseract-ocr\n",
            "ERROR: Failed to build installable wheels for some pyproject.toml based projects (tesseract-ocr)\n"
          ]
        }
      ],
      "source": [
        "pip install datasets kaggle PyMuPDF Pillow tf-keras tesseract-ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "USju2g6AN31r",
        "outputId": "1f906037-483d-4574-f8cd-e77f20271262"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# def setup_kaggle():\n",
        "#   from google.colab import files\n",
        "#   uploaded = files.upload()\n",
        "#   !chmod 600 kaggle.json\n",
        "#   %mkdir -p /root/.kaggle/\n",
        "#   %mv kaggle.json /root/.kaggle/\n",
        "\n",
        "# setup_kaggle()\n",
        "\n",
        "#RUN THIS COMMAND ON TERMINAL --> TO CONNECT TO KAGGLE  OR RUN HERE WITH OS\n",
        "import os\n",
        "\n",
        "os.system(r'icacls \"C:\\Users\\annap\\.kaggle\\kaggle.json\" /inheritance:r /grant:r annap:R')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AqZUhSSNNDLw"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\activations_tf.py:22\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tf_keras'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1863\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1381\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1354\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1325\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:929\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:994\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_tf_utils.py:38\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\activations_tf.py:27\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     31\u001b[0m         )\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
            "\u001b[1;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1863\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1381\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1354\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1325\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:929\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:994\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\integrations\\integration_utils.py:36\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1406\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1851\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1851\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1852\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1865\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1864\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1865\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1866\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1867\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1868\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1863\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1381\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1354\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1325\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:929\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:994\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\trainer.py:42\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Integrations must be imported before ML frameworks:\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     43\u001b[0m     get_reporting_integration_callbacks,\n\u001b[0;32m     44\u001b[0m )\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# isort: on\u001b[39;00m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1406\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1851\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1851\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1852\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1865\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1864\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1865\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1866\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1867\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1868\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 23\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# from nltk.tokenize import word_tokenize\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# from nltk import pos_tag\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# from nltk.corpus import stopwords\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# from sklearn import model_selection, naive_bayes, svm\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# from sklearn.metrics import accuracy_score\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoProcessor, AutoModelForSequenceClassification, TrainingArguments, Trainer\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset  \u001b[38;5;66;03m#, DatasetDict\u001b[39;00m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1406\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1851\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1849\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1851\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1852\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1853\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1865\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1864\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1865\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1866\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1867\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1868\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
          ]
        }
      ],
      "source": [
        "import kaggle\n",
        "kaggle.api.authenticate()\n",
        "# import recmetrics\n",
        "\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import fitz\n",
        "import os\n",
        "import cv2\n",
        "import re\n",
        "# from nltk.tokenize import word_tokenize\n",
        "# from nltk import pos_tag\n",
        "# from nltk.corpus import stopwords\n",
        "# from nltk.stem import WordNetLemmatizer\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from collections import defaultdict\n",
        "# from nltk.corpus import wordnet as wn\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn import model_selection, naive_bayes, svm\n",
        "# from sklearn.metrics import accuracy_score\n",
        "from transformers import AutoProcessor, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from datasets import Dataset  #, DatasetDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjRaeCS22MMB"
      },
      "source": [
        "## From JPG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6vEGawQ2NeQ",
        "outputId": "f9b2dfc5-f0f4-4609-83d1-cd65822be516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/shaz13/real-world-documents-collections\n",
            "['docs-sm']\n"
          ]
        }
      ],
      "source": [
        "dataset_path = 'shaz13/real-world-documents-collections'\n",
        "kaggle.api.dataset_download_files(dataset_path, path=dataset_path, unzip=True)\n",
        "print(os.listdir(dataset_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lVe2KUyK4QbI",
        "outputId": "b528eb06-6645-4ec3-cea2-941aa93df42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0000137486.jpg', '0000192502.jpg', '0000226471.jpg', '0000227351.jpg', '0000333206.jpg', '0000542607.jpg', '0001136788.jpg', '0001219743.jpg', '0001219844.jpg', '0001233629.jpg', '0001453135.jpg', '0011519293.jpg', '0011929750.jpg', '0011929754.jpg', '0011930170.jpg', '0011991025.jpg', '0012179618.jpg', '0012193483.jpg', '0012287015.jpg', '0013041942.jpg', '0013043203.jpg', '0013122156.jpg', '0013267193.jpg', '0060026309.jpg', '0060027381.jpg', '0060031784.jpg', '0060032039.jpg', '0060046962.jpg', '0060051594.jpg', '0060075043.jpg', '0060080760.jpg', '0060082098.jpg', '0060083495.jpg', '0060095587.jpg', '0060095589.jpg', '0060116328.jpg', '0060121960.jpg', '0060201834.jpg', '0060207574.jpg', '0060281129.jpg', '0060284223.jpg', '00621985.jpg', '00920638.jpg', '00920717.jpg', '01145176.jpg', '01398469.jpg', '03638969.jpg', '03660266.jpg', '03700650.jpg', '03724966.jpg', '03750991.jpg', '1000031431.jpg', '10399076.jpg', '10399232.jpg', '11235021_11235022.jpg', '11238840.jpg', '2001205675.jpg', '2001207806_2001207807.jpg', '2001207874.jpg', '2015066906.jpg', '2021636830.jpg', '2023186187.jpg', '2023322384.jpg', '2023550756.jpg', '2023921600.jpg', '2024525606.jpg', '2024525914.jpg', '2025847098.jpg', '2026004159.jpg', '2026486780.jpg', '2026486823.jpg', '2028691757.jpg', '2028691805_2028691806.jpg', '2028694058.jpg', '2028697984.jpg', '2028699251.jpg', '2028704073.jpg', '2028705019.jpg', '2028706274.jpg', '2028706570.jpg', '2028707266.jpg', '2028707700.jpg', '2028708390.jpg', '2028708554.jpg', '2028710092.jpg', '2028712208.jpg', '2028716484.jpg', '2028716668.jpg', '2028717388.jpg', '2028718888.jpg', '2028719456.jpg', '2028719939_2028719940.jpg', '2028721083.jpg', '2028722501.jpg', '2028724070.jpg', '2028724447.jpg', '2028725808.jpg', '2028726558.jpg', '2028727366.jpg', '2028728093.jpg', '2028729611.jpg', '2028729939.jpg', '2028741327_2028741328.jpg', '2028741476.jpg', '2028743452_2028743453.jpg', '2028747402_2028747403.jpg', '2029194963.jpg', '2029370141.jpg', '2029370154.jpg', '2029370462.jpg', '2029377237.jpg', '2029378210.jpg', '2030138144.jpg', '2030403783.jpg', '2041158058.jpg', '2041619314.jpg', '2042757520.jpg', '2044696250.jpg', '2045150408.jpg', '2048163101.jpg', '2048373725.jpg', '2049431637.jpg', '2049433368.jpg', '2061832122.jpg', '2062173086.jpg', '2062897991.jpg', '2063113437.jpg', '2063162451_2452.jpg', '2063170427.jpg', '2063178328.jpg', '2063216949.jpg', '2063300411.jpg', '2063321228.jpg', '2063321345.jpg', '2063576912.jpg', '2063608519.jpg', '2063610066.jpg', '2063780011.jpg', '2071030591.jpg', '2071533746.jpg', '2072484129.jpg', '2072653060.jpg', '2072957896.jpg', '2072958016_8017.jpg', '2073071216.jpg', '2074104178.jpg', '2074104267.jpg', '2074104343.jpg', '2076999610_9611.jpg', '2077990205.jpg', '2080143458.jpg', '2084020004.jpg', '2084020048.jpg', '2084020226.jpg', '2084021794.jpg', '2084022132.jpg', '2084022189.jpg', '2084022308.jpg', '2084022332.jpg', '2084022751.jpg', '2084022815.jpg', '2084024647.jpg', '2084024865.jpg', '2084061020.jpg', '2084061095.jpg', '2084061297.jpg', '2084342625.jpg', '2085669419.jpg', '2501226749.jpg', '2501335075.jpg', '2501374034_2501374035.jpg', '2505153109.jpg', '2505407626.jpg', '2505414281.jpg', '500234640+-4640.jpg', '500234675+-4675.jpg', '50120566-0566.jpg', '501703529+-3529.jpg', '501961404.jpg', '502197661.jpg', '505850844.jpg', '506023794_506023798.jpg', '506271023.jpg', '509592495_509592499.jpg', '511349392+-9392.jpg', '511505606+-5608.jpg', '513168276_513168277.jpg', '513261894_513261895.jpg', '518027475_518027477.jpg', '518029936.jpg', '518255073+-5074.jpg', '518279202+-9206.jpg', '518434787+-4793.jpg', '518658731+-8731.jpg', '520761472+-1478.jpg', '522896255+-6258.jpg', '524425631+-5636.jpg', '530003729+-3730.jpg', '80211531.jpg', '80211559.jpg', '80233761.jpg', '80233857.jpg', '80701185.jpg', '80702018.jpg', '80703441.jpg', '80703850.jpg', '80704008.jpg', '80721675.jpg', '82894853.jpg', '83093314.jpg', '83553535_3536.jpg', '83553602_3608.jpg', '85701956.jpg', '86453264.jpg', '86462730.jpg', '86462778.jpg', '86618993.jpg', '87052618.jpg', '87064415.jpg', '87064443-a_87064443.jpg', '87064464.jpg', '87064937.jpg', '87065276.jpg', '87066913.jpg', '87103978.jpg', '87104373.jpg', '87148930_87148933.jpg', '87149523_87149526.jpg', '87683565.jpg', '88131587.jpg', '88131634.jpg', '88131701.jpg', '88131802.jpg', '88132141.jpg', '88266768a.jpg', '89000187.jpg', '89000431.jpg', '89000786.jpg', '89000889.jpg', '89001134.jpg', '89001193.jpg', '89001376.jpg', '89001625.jpg', '89001738.jpg', '91505705.jpg', '91506390_6391.jpg', '91507140.jpg', '91507253.jpg', '91514421.jpg', '91515217.jpg', '91515307.jpg', '91515363.jpg', '91575143.jpg', '91658313.jpg', '91659229.jpg', '91661681.jpg', '91664823.jpg', '91810227.jpg', '91814706.jpg', '92224513.jpg', '92226198.jpg', '92227544_7545.jpg', '92242531.jpg', '92248313.jpg', '92678319.jpg', '92679791.jpg', '92857175.jpg', '92871560.jpg', '93121403.jpg', '93216911.jpg', '93413375.jpg', '93416592.jpg', '94389950.jpg', '94416171.jpg', '95602385.jpg', '95602471.jpg', '95824354.jpg', '95824480.jpg', '95824806.jpg', '95824822.jpg', '95824834.jpg', '96054429.jpg', '96057185.jpg', '96433725.jpg', '98776481.jpg', 'CTRCONTRACTS001598-1.jpg', 'CTRCONTRACTS009895-9.jpg', 'CTRCONTRACTS010472-0.jpg', 'CTRCONTRACTS022507-2.jpg', 'CTRCONTRACTS024759-4.jpg', 'CTRSP-FILES009859-98.jpg', 'ti08670559.jpg', 'ti10161552.jpg', 'ti10161636.jpg', 'ti16310446.jpg', 'ti16310591.jpg', 'ti16310868.jpg', 'ti16352085.jpg', 'ti17120055.jpg', 'ti17120567.jpg', 'ti31689101.jpg', 'tob04705.73_tob04705.76.jpg']\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(500)\n",
        "#invoices\n",
        "invoice_path = f'{dataset_path}/docs-sm/invoice'\n",
        "print(os.listdir(invoice_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37mHdboyVOKt"
      },
      "source": [
        "# Utility Functions for LayoutMv3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJuhVHhAUkbx"
      },
      "outputs": [],
      "source": [
        "def normalize_box(bbox, w, h):\n",
        "    return [\n",
        "        int(bbox[0]*(1000/w)),\n",
        "        int(bbox[1]*(1000/h)),\n",
        "        int(bbox[2]*(1000/w)),\n",
        "        int(bbox[3]*(1000/h)),\n",
        "    ]\n",
        "\n",
        "\n",
        "def unnormalize_box(bbox, w, h):\n",
        "    return [\n",
        "        w * (bbox[0] / 1000),\n",
        "        hash * (bbox[1] / 1000),\n",
        "        w * (bbox[2] / 1000),\n",
        "        h * (bbox[3] / 1000),\n",
        "    ]\n",
        "\n",
        "\n",
        "#comparing bounding boxes for debugging\n",
        "def compare_boxes(b1, b2):\n",
        "    b1 = np.array([c for c in b1])\n",
        "    b2 = np.array([c for c in b2])\n",
        "    equal = np.array_equal(b1, b2)\n",
        "    return equal\n",
        "\n",
        "\n",
        "def adjacent(w1, w2):\n",
        "    if w1['label'] == w2['label'] and abs(w1['id'] - w2['id']) == 1:\n",
        "      return True\n",
        "    return False\n",
        "\n",
        "\n",
        "# def load_model(model_path):\n",
        "#     model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "#     return model\n",
        "\n",
        "\n",
        "# def load_processor():\n",
        "#     processor = AutoProcessor.from_pretrained(\n",
        "#         \"microsoft/layoutlmv3-base\", apply_ocr=False)\n",
        "#     return processor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp3SnJQ4VM-O"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_285d_BWpum6"
      },
      "outputs": [],
      "source": [
        "'''tesseract runs OCR on images to recognize text'''\n",
        "def run_tesseract_on_image(image_path):  # -> tsv output path\n",
        "    # image_path = image_path.replace(\"\\\\\", \"/\") \n",
        "\n",
        "    base_path = r\"C:\\Users\\annap\\Desktop\\Year3\\stats\\final_project\" \n",
        "    image_path = os.path.join(base_path, image_path)  \n",
        "    image_path = os.path.normpath(image_path) \n",
        "    print(\"IMAGE PATH\", image_path)\n",
        "\n",
        "    # image_path = r\"C:\\Users\\annap\\Desktop\\Year3\\stats\\final_project\\\"\" + image_path\n",
        "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "    #DEBUG\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Unable to read image: {image_path}\")   \n",
        "\n",
        "\n",
        "    tsv_directory = os.path.abspath(os.path.join(os.getcwd(), \"tsv\"))\n",
        "    if not os.path.exists(tsv_directory):\n",
        "        os.makedirs(tsv_directory)\n",
        "\n",
        "    tsv_output_path = os.path.join(tsv_directory, f\"{image_name}.tsv\")\n",
        "\n",
        "    print(f\"Running Tesseract on image: {image_path}\")\n",
        "    print(f\"Saving TSV to: {tsv_output_path}\")\n",
        "    print(f\"Command: tesseract \\\"{image_path}\\\" \\\"{tsv_output_path}\\\" -l eng tsv\")\n",
        "\n",
        "\n",
        "    tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "    error_code = os.system(f'\"{tesseract_cmd}\" \"{image_path}\" \"{tsv_output_path}\" -l eng tsv')\n",
        "\n",
        "    if not error_code:\n",
        "      return tsv_output_path              #saves extracted text from image in the tsv file\n",
        "    else:\n",
        "      raise ValueError('Error running Tesseract on image/verify image format PNG,JPG,JPEG')\n",
        "\n",
        "\n",
        "\n",
        "'''reads the file generated above, removes empty/missing entries,\n",
        "iterates through the cleaned dataset and stores words and bbox coordinates'''\n",
        "def clean_tesseract_output(tsv_output_path):\n",
        "    ocr_df = pd.read_csv(tsv_output_path, sep='\\t')\n",
        "    ocr_df = ocr_df.dropna()\n",
        "    ocr_df = ocr_df.drop(ocr_df[ocr_df.text.str.strip() == ''].index)\n",
        "    # text_output = ' '.join(ocr_df.text.tolist())\n",
        "\n",
        "    words = []\n",
        "    for index, row in ocr_df.iterrows():\n",
        "      word = {}\n",
        "      origin_box = [row['left'], row['top'], row['left'] + row['width'], row['top']+row['height']]\n",
        "      word['word_text'] = row['text']\n",
        "      word['word_box'] = origin_box\n",
        "      words.append(word)\n",
        "\n",
        "    return words          #array of dicts that include bbox coords and words details\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def prepare_batch_for_inference(image_paths):\n",
        "#     tesseract_outputs = [run_tesseract_on_image(image_path) for image_path in image_paths]    # tesseract_outputs is list of paths\n",
        "#     clean_outputs = [clean_tesseract_output(tsv_path) for tsv_path in tesseract_outputs]        # clean_outputs is a list of lists\n",
        "\n",
        "#     word_lists = [[word['word_text'] for word in clean_output] for clean_output in clean_outputs]\n",
        "#     boxes_lists = [[word['word_box'] for word in clean_output] for clean_output in clean_outputs]\n",
        "\n",
        "#     inference_batch = {\n",
        "#       \"image_path\": image_paths,\n",
        "#       \"bboxes\": boxes_lists,\n",
        "#       \"words\": word_lists\n",
        "#     }\n",
        "\n",
        "#     return inference_batch\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "C5Xe2P9C2dAp",
        "outputId": "4cfc5bc9-d07c-4e15-8291-b3270f253dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shaz13/real-world-documents-collections/docs-sm/invoice\n",
            "Valid image: 0000137486.jpg\n",
            "IMAGE PATH C:\\Users\\annap\\Desktop\\Year3\\stats\\final_project\\shaz13\\real-world-documents-collections\\docs-sm\\invoice\\0000137486.jpg\n",
            "Running Tesseract on image: C:\\Users\\annap\\Desktop\\Year3\\stats\\final_project\\shaz13\\real-world-documents-collections\\docs-sm\\invoice\\0000137486.jpg\n",
            "Saving TSV to: c:\\Users\\annap\\Desktop\\Year3\\stats\\final_project\\tsv\\0000137486.tsv\n",
            "Command: tesseract \"C:\\Users\\annap\\Desktop\\Year3\\stats\\final_project\\shaz13\\real-world-documents-collections\\docs-sm\\invoice\\0000137486.jpg\" \"c:\\Users\\annap\\Desktop\\Year3\\stats\\final_project\\tsv\\0000137486.tsv\" -l eng tsv\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Error running Tesseract on image/verify image format PNG,JPG,JPEG",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[70], line 62\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValid image: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(invoice_path, filename)\n\u001b[1;32m---> 62\u001b[0m words,bboxes \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_tesseract_tsv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# invoice_data = extract_invoice_data(text)\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# invoice_data[\"File Name\"] = filename\u001b[39;00m\n\u001b[0;32m     65\u001b[0m invoice_data_list\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: filename,\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: words,\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m: bboxes,\n\u001b[0;32m     69\u001b[0m })\n",
            "Cell \u001b[1;32mIn[70], line 3\u001b[0m, in \u001b[0;36mextract_text_bboxes\u001b[1;34m(image_path, use_tesseract_tsv)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_bboxes\u001b[39m(image_path, use_tesseract_tsv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_tesseract_tsv:                     \u001b[38;5;66;03m#tesseract TSV\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m       tsv_path \u001b[38;5;241m=\u001b[39m \u001b[43mrun_tesseract_on_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m       words_boxes \u001b[38;5;241m=\u001b[39m clean_tesseract_output(tsv_path)\n\u001b[0;32m      5\u001b[0m       words \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m words_boxes]\n",
            "Cell \u001b[1;32mIn[69], line 34\u001b[0m, in \u001b[0;36mrun_tesseract_on_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m     32\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tsv_output_path              \u001b[38;5;66;03m#saves extracted text from image in the tsv file\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 34\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError running Tesseract on image/verify image format PNG,JPG,JPEG\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[1;31mValueError\u001b[0m: Error running Tesseract on image/verify image format PNG,JPG,JPEG"
          ]
        }
      ],
      "source": [
        "def extract_text_bboxes(image_path, use_tesseract_tsv=True):\n",
        "    if use_tesseract_tsv:                     #tesseract TSV\n",
        "      tsv_path = run_tesseract_on_image(image_path)\n",
        "      words_boxes = clean_tesseract_output(tsv_path)\n",
        "      words = [item['word_text'] for item in words_boxes]\n",
        "      bboxes = [item['word_box'] for item in words_boxes]\n",
        "\n",
        "    # else:                                     #pytesseract\n",
        "    #   img = cv2.imread(image_path)\n",
        "    #   gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    #   gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    #   _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    #   extracted_text = pytesseract.image_to_string(thresh)\n",
        "\n",
        "    #   data = pytesseract.image_to_data(thresh, output_type=pytesseract.Output.DICT)   #extracts words, bboxes\n",
        "\n",
        "    #   words, bboxes = [], []\n",
        "    #   h, w, _ = img.shape\n",
        "\n",
        "    #   for i in range(len(data[\"text\"])):\n",
        "    #     if data[\"text\"][i].strip():\n",
        "    #       words.append(data[\"text\"][i])\n",
        "    #       x,y,w,h = data[\"left\"][i], data[\"top\"][i], data[\"width\"][i], data[\"height\"][i]\n",
        "    #       bbox = [\n",
        "    #           int((x/w)*1000),\n",
        "    #           int((y/h)*1000),\n",
        "    #           int(((x + w)/w) * 1000),\n",
        "    #           int(((y + h)/h) *1000)]      #1000x1000  normalizes bboxes\n",
        "    #       bboxes.append(bbox)\n",
        "\n",
        "    return words, bboxes\n",
        "\n",
        "\n",
        "\n",
        "def clean_text(df):\n",
        "    # df = df.dropna()\n",
        "    df = df.explode(\"tokens\")\n",
        "    df = df[df[\"tokens\"].str.strip() != '']\n",
        "\n",
        "    # text_output = ' '.join(df.text.tolist())\n",
        "\n",
        "    words = []\n",
        "    for index, row in df.iterrows():\n",
        "        word = {}\n",
        "        origin_box = row['bboxes']\n",
        "        word['word_text'] = row['tokens']\n",
        "        word['word_box'] = origin_box\n",
        "        words.append(word)\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "\n",
        "#prepares for inference\n",
        "invoice_data_list = []\n",
        "print(invoice_path)\n",
        "\n",
        "for filename in os.listdir(invoice_path):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg',)):\n",
        "        print(f\"Valid image: {filename}\")\n",
        "        image_path = os.path.join(invoice_path, filename)\n",
        "        words,bboxes = extract_text_bboxes(image_path, use_tesseract_tsv=True)\n",
        "        # invoice_data = extract_invoice_data(text)\n",
        "        # invoice_data[\"File Name\"] = filename\n",
        "        invoice_data_list.append({\n",
        "            \"file_name\": filename,\n",
        "            \"tokens\": words,\n",
        "            \"bboxes\": bboxes,\n",
        "        })\n",
        "    else:\n",
        "        print(f\"Skipping non-image file: {filename}\")\n",
        "\n",
        "df = pd.DataFrame(invoice_data_list)\n",
        "# print(df)\n",
        "# print(df.columns)\n",
        "\n",
        "\n",
        "df = clean_text(df)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JMRlBDktE1E"
      },
      "source": [
        "LayoutMv3 needs textual and spatial information. So, we need the bounding boxes of where the text is positioned within the picture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m70NuIuvrghL"
      },
      "outputs": [],
      "source": [
        "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n",
        "\n",
        "#convert into huggnig face dataset\n",
        "hf_dataset = Dataset.from_pandas(df)\n",
        "print(hf_dataset[0])   #check it worked\n",
        "\n",
        "\n",
        "#passes words/bboxes into the layoutmv3 processer\n",
        "def preprocess(example, img_path):\n",
        "  img = Image.open(image_path.convert(\"RBG\"))\n",
        "  encoding = processor(\n",
        "      images=img,\n",
        "      text=example[\"tokens\"],\n",
        "      boxes=example[\"bboxes\"],\n",
        "      truncation=True,\n",
        "      padding=\"max_length\"\n",
        "  )\n",
        "  return encoding\n",
        "\n",
        "\n",
        "dataset = hf_dataset.train_test_split(test_size=0.2)\n",
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0RYjn4iKhKI"
      },
      "source": [
        "# Invoice Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xs0S3ZKTKi5A"
      },
      "outputs": [],
      "source": [
        "# we will need to recreate this for all categories\n",
        "def extract_invoice_data(text):\n",
        "    data = {}\n",
        "\n",
        "    data[\"Invoice Number\"] = re.search(r'Invoice\\s*No[:#]?\\s*([\\w-]+)', text, re.IGNORECASE)\n",
        "    data[\"Invoice Date\"] = re.search(r'Invoice\\s*Date[:#]?\\s*([\\d{2}/\\d{2}/\\d{4}]+)', text, re.IGNORECASE)\n",
        "    data[\"Due Date\"] = re.search(r'Due\\s*Date[:#]?\\s*([\\d{2}/\\d{2}/\\d{4}]+)', text, re.IGNORECASE)\n",
        "    data[\"Issuer Name\"] = re.search(r'From[:#]?\\s*([A-Za-z\\s]+)', text, re.IGNORECASE)\n",
        "    data[\"Recipient Name\"] = re.search(r'To[:#]?\\s*([A-Za-z\\s]+)', text, re.IGNORECASE)\n",
        "    data[\"Total Amount\"] = re.search(r'Total\\s*Amount[:#]?\\s*([\\d,]+\\.?\\d{2})', text, re.IGNORECASE)\n",
        "\n",
        "    for key, value in data.items():\n",
        "        data[key] = value.group(1) if value else \"Not Found\"\n",
        "\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw1YbzEuKLAi"
      },
      "source": [
        "# LayoutMv3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XapN_qyKNaT"
      },
      "outputs": [],
      "source": [
        "#pretrained layoutmv3 model\n",
        "model = AutoModelForSequenceClassification(\"microsoft/layoutlmv3-base\", num_labels=4)\n",
        "\n",
        "train_args = TrainingArguments(output_dir=\"./layoutlmv3_results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=5,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\"\n",
        "    )\n",
        "\n",
        "\n",
        "trainer= Trainer(\n",
        "    model=model,\n",
        "    args=train_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        "    )\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iECvxFshMXZt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

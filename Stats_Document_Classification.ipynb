{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.9.0 (tags/v3.9.0:9cf6752, Oct  5 2020, 15:34:40) [MSC v.1927 64 bit (AMD64)]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIGTQuvp67YI",
        "outputId": "59efc32d-ed35-40e3-ae38-7fbf6c58d1e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.4.1)\n",
            "Requirement already satisfied: kaggle in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.7.4.2)\n",
            "Requirement already satisfied: PyMuPDF in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.25.4)\n",
            "Requirement already satisfied: Pillow in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (11.1.0)\n",
            "Requirement already satisfied: pytesseract in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.3.13)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.11.0.86)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2024.12.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.11.14)\n",
            "Requirement already satisfied: xxhash in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: filelock in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (19.0.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from datasets) (2.2.3)\n",
            "Requirement already satisfied: packaging in c:\\users\\annap\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: six>=1.10 in c:\\users\\annap\\appdata\\roaming\\python\\python39\\site-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kaggle) (49.2.1)\n",
            "Requirement already satisfied: protobuf in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kaggle) (5.29.4)\n",
            "Requirement already satisfied: webencodings in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kaggle) (3.4.1)\n",
            "Requirement already satisfied: text-unidecode in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\annap\\appdata\\roaming\\python\\python39\\site-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: idna in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kaggle) (3.10)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: bleach in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (6.2.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0; python_version < \"3.11\" in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\annap\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\annap\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 20.2.3; however, version 25.0.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install datasets kaggle PyMuPDF Pillow pytesseract opencv-python "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp39-cp39-win_amd64.whl (204.1 MB)\n",
            "Collecting jinja2\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: fsspec in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch) (2024.12.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\annap\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.12.2)\n",
            "Collecting sympy==1.13.1; python_version >= \"3.9\"\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "Collecting networkx\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\annap\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting mpmath<1.4,>=1.1.0\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: jinja2, mpmath, sympy, networkx, torch\n",
            "Successfully installed jinja2-3.1.6 mpmath-1.3.0 networkx-3.2.1 sympy-1.13.1 torch-2.6.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: The script isympy.exe is installed in 'c:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'c:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python39\\Scripts' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "WARNING: You are using pip version 20.2.3; however, version 25.0.1 is available.\n",
            "You should consider upgrading via the 'c:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "USju2g6AN31r",
        "outputId": "1f906037-483d-4574-f8cd-e77f20271262"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#RUN THIS COMMAND ON TERMINAL --> TO CONNECT TO KAGGLE  OR RUN HERE WITH OS\n",
        "import os\n",
        "\n",
        "os.system(r'icacls \"C:\\Users\\annap\\.kaggle\\kaggle.json\" /inheritance:r /grant:r annap:R')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "AqZUhSSNNDLw"
      },
      "outputs": [],
      "source": [
        "import kaggle\n",
        "kaggle.api.authenticate()\n",
        "\n",
        "from PIL import Image\n",
        "import pytesseract\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import re\n",
        "\n",
        "# from transformers import AutoProcessor, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "from huggingface_hub import hf_hub_download\n",
        "import torch\n",
        "from transformers import LayoutLMv3ForSequenceClassification, LayoutLMv3Tokenizer\n",
        "from datasets import Dataset  \n",
        "import subprocess\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjRaeCS22MMB"
      },
      "source": [
        "## From JPG\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6vEGawQ2NeQ",
        "outputId": "f9b2dfc5-f0f4-4609-83d1-cd65822be516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/shaz13/real-world-documents-collections\n",
            "['docs-sm']\n"
          ]
        }
      ],
      "source": [
        "dataset_path = 'shaz13/real-world-documents-collections'\n",
        "kaggle.api.dataset_download_files(dataset_path, path=dataset_path, unzip=True)\n",
        "print(os.listdir(dataset_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lVe2KUyK4QbI",
        "outputId": "b528eb06-6645-4ec3-cea2-941aa93df42c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['0000137486.jpg', '0000192502.jpg', '0000226471.jpg', '0000227351.jpg', '0000333206.jpg', '0000542607.jpg', '0001136788.jpg', '0001219743.jpg', '0001219844.jpg', '0001233629.jpg', '0001453135.jpg', '0011519293.jpg', '0011929750.jpg', '0011929754.jpg', '0011930170.jpg', '0011991025.jpg', '0012179618.jpg', '0012193483.jpg', '0012287015.jpg', '0013041942.jpg', '0013043203.jpg', '0013122156.jpg', '0013267193.jpg', '0060026309.jpg', '0060027381.jpg', '0060031784.jpg', '0060032039.jpg', '0060046962.jpg', '0060051594.jpg', '0060075043.jpg', '0060080760.jpg', '0060082098.jpg', '0060083495.jpg', '0060095587.jpg', '0060095589.jpg', '0060116328.jpg', '0060121960.jpg', '0060201834.jpg', '0060207574.jpg', '0060281129.jpg', '0060284223.jpg', '00621985.jpg', '00920638.jpg', '00920717.jpg', '01145176.jpg', '01398469.jpg', '03638969.jpg', '03660266.jpg', '03700650.jpg', '03724966.jpg', '03750991.jpg', '1000031431.jpg', '10399076.jpg', '10399232.jpg', '11235021_11235022.jpg', '11238840.jpg', '2001205675.jpg', '2001207806_2001207807.jpg', '2001207874.jpg', '2015066906.jpg', '2021636830.jpg', '2023186187.jpg', '2023322384.jpg', '2023550756.jpg', '2023921600.jpg', '2024525606.jpg', '2024525914.jpg', '2025847098.jpg', '2026004159.jpg', '2026486780.jpg', '2026486823.jpg', '2028691757.jpg', '2028691805_2028691806.jpg', '2028694058.jpg', '2028697984.jpg', '2028699251.jpg', '2028704073.jpg', '2028705019.jpg', '2028706274.jpg', '2028706570.jpg', '2028707266.jpg', '2028707700.jpg', '2028708390.jpg', '2028708554.jpg', '2028710092.jpg', '2028712208.jpg', '2028716484.jpg', '2028716668.jpg', '2028717388.jpg', '2028718888.jpg', '2028719456.jpg', '2028719939_2028719940.jpg', '2028721083.jpg', '2028722501.jpg', '2028724070.jpg', '2028724447.jpg', '2028725808.jpg', '2028726558.jpg', '2028727366.jpg', '2028728093.jpg', '2028729611.jpg', '2028729939.jpg', '2028741327_2028741328.jpg', '2028741476.jpg', '2028743452_2028743453.jpg', '2028747402_2028747403.jpg', '2029194963.jpg', '2029370141.jpg', '2029370154.jpg', '2029370462.jpg', '2029377237.jpg', '2029378210.jpg', '2030138144.jpg', '2030403783.jpg', '2041158058.jpg', '2041619314.jpg', '2042757520.jpg', '2044696250.jpg', '2045150408.jpg', '2048163101.jpg', '2048373725.jpg', '2049431637.jpg', '2049433368.jpg', '2061832122.jpg', '2062173086.jpg', '2062897991.jpg', '2063113437.jpg', '2063162451_2452.jpg', '2063170427.jpg', '2063178328.jpg', '2063216949.jpg', '2063300411.jpg', '2063321228.jpg', '2063321345.jpg', '2063576912.jpg', '2063608519.jpg', '2063610066.jpg', '2063780011.jpg', '2071030591.jpg', '2071533746.jpg', '2072484129.jpg', '2072653060.jpg', '2072957896.jpg', '2072958016_8017.jpg', '2073071216.jpg', '2074104178.jpg', '2074104267.jpg', '2074104343.jpg', '2076999610_9611.jpg', '2077990205.jpg', '2080143458.jpg', '2084020004.jpg', '2084020048.jpg', '2084020226.jpg', '2084021794.jpg', '2084022132.jpg', '2084022189.jpg', '2084022308.jpg', '2084022332.jpg', '2084022751.jpg', '2084022815.jpg', '2084024647.jpg', '2084024865.jpg', '2084061020.jpg', '2084061095.jpg', '2084061297.jpg', '2084342625.jpg', '2085669419.jpg', '2501226749.jpg', '2501335075.jpg', '2501374034_2501374035.jpg', '2505153109.jpg', '2505407626.jpg', '2505414281.jpg', '500234640+-4640.jpg', '500234675+-4675.jpg', '50120566-0566.jpg', '501703529+-3529.jpg', '501961404.jpg', '502197661.jpg', '505850844.jpg', '506023794_506023798.jpg', '506271023.jpg', '509592495_509592499.jpg', '511349392+-9392.jpg', '511505606+-5608.jpg', '513168276_513168277.jpg', '513261894_513261895.jpg', '518027475_518027477.jpg', '518029936.jpg', '518255073+-5074.jpg', '518279202+-9206.jpg', '518434787+-4793.jpg', '518658731+-8731.jpg', '520761472+-1478.jpg', '522896255+-6258.jpg', '524425631+-5636.jpg', '530003729+-3730.jpg', '80211531.jpg', '80211559.jpg', '80233761.jpg', '80233857.jpg', '80701185.jpg', '80702018.jpg', '80703441.jpg', '80703850.jpg', '80704008.jpg', '80721675.jpg', '82894853.jpg', '83093314.jpg', '83553535_3536.jpg', '83553602_3608.jpg', '85701956.jpg', '86453264.jpg', '86462730.jpg', '86462778.jpg', '86618993.jpg', '87052618.jpg', '87064415.jpg', '87064443-a_87064443.jpg', '87064464.jpg', '87064937.jpg', '87065276.jpg', '87066913.jpg', '87103978.jpg', '87104373.jpg', '87148930_87148933.jpg', '87149523_87149526.jpg', '87683565.jpg', '88131587.jpg', '88131634.jpg', '88131701.jpg', '88131802.jpg', '88132141.jpg', '88266768a.jpg', '89000187.jpg', '89000431.jpg', '89000786.jpg', '89000889.jpg', '89001134.jpg', '89001193.jpg', '89001376.jpg', '89001625.jpg', '89001738.jpg', '91505705.jpg', '91506390_6391.jpg', '91507140.jpg', '91507253.jpg', '91514421.jpg', '91515217.jpg', '91515307.jpg', '91515363.jpg', '91575143.jpg', '91658313.jpg', '91659229.jpg', '91661681.jpg', '91664823.jpg', '91810227.jpg', '91814706.jpg', '92224513.jpg', '92226198.jpg', '92227544_7545.jpg', '92242531.jpg', '92248313.jpg', '92678319.jpg', '92679791.jpg', '92857175.jpg', '92871560.jpg', '93121403.jpg', '93216911.jpg', '93413375.jpg', '93416592.jpg', '94389950.jpg', '94416171.jpg', '95602385.jpg', '95602471.jpg', '95824354.jpg', '95824480.jpg', '95824806.jpg', '95824822.jpg', '95824834.jpg', '96054429.jpg', '96057185.jpg', '96433725.jpg', '98776481.jpg', 'CTRCONTRACTS001598-1.jpg', 'CTRCONTRACTS009895-9.jpg', 'CTRCONTRACTS010472-0.jpg', 'CTRCONTRACTS022507-2.jpg', 'CTRCONTRACTS024759-4.jpg', 'CTRSP-FILES009859-98.jpg', 'ti08670559.jpg', 'ti10161552.jpg', 'ti10161636.jpg', 'ti16310446.jpg', 'ti16310591.jpg', 'ti16310868.jpg', 'ti16352085.jpg', 'ti17120055.jpg', 'ti17120567.jpg', 'ti31689101.jpg', 'tob04705.73_tob04705.76.jpg']\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(500)\n",
        "#invoices\n",
        "invoice_path = f'{dataset_path}/docs-sm/invoice'\n",
        "print(os.listdir(invoice_path))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37mHdboyVOKt"
      },
      "source": [
        "# Utility Functions for LayoutMv3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UJuhVHhAUkbx"
      },
      "outputs": [],
      "source": [
        "def normalize_box(bbox, w, h):\n",
        "    return [\n",
        "        int(bbox[0]*(1000/w)),\n",
        "        int(bbox[1]*(1000/h)),\n",
        "        int(bbox[2]*(1000/w)),\n",
        "        int(bbox[3]*(1000/h)),\n",
        "    ]\n",
        "\n",
        "\n",
        "def unnormalize_box(bbox, w, h):\n",
        "    return [\n",
        "        w * (bbox[0] / 1000),\n",
        "        hash * (bbox[1] / 1000),\n",
        "        w * (bbox[2] / 1000),\n",
        "        h * (bbox[3] / 1000),\n",
        "    ]\n",
        "\n",
        "\n",
        "#comparing bounding boxes for debugging\n",
        "def compare_boxes(b1, b2):\n",
        "    b1 = np.array([c for c in b1])\n",
        "    b2 = np.array([c for c in b2])\n",
        "    equal = np.array_equal(b1, b2)\n",
        "    return equal\n",
        "\n",
        "\n",
        "def adjacent(w1, w2):\n",
        "    if w1['label'] == w2['label'] and abs(w1['id'] - w2['id']) == 1:\n",
        "      return True\n",
        "    return False\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp3SnJQ4VM-O"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_285d_BWpum6"
      },
      "outputs": [],
      "source": [
        "'''tesseract runs OCR on images to recognize text'''\n",
        "def run_tesseract_on_image(image_path):  # -> tsv output path\n",
        "    # image_path = image_path.replace(\"\\\\\", \"/\") \n",
        "\n",
        "    base_path = r\"C:\\Users\\annap\\Desktop\\Year3\\stats\\document-classification\" \n",
        "    image_path = os.path.join(base_path, image_path)  \n",
        "    image_path = os.path.normpath(image_path) \n",
        "    print(\"IMAGE PATH\", image_path)\n",
        "\n",
        "    # image_path = r\"C:\\Users\\annap\\Desktop\\Year3\\stats\\final_project\\\"\" + image_path\n",
        "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "    print(\"image name after supposedly removing the .tsv\", image_name)\n",
        "\n",
        "    #DEBUG\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Unable to read image: {image_path}\")   \n",
        "    else:\n",
        "        print(f\"Image {image_path} loaded successfully.\")  \n",
        "\n",
        "\n",
        "    tsv_directory = os.path.abspath(os.path.join(os.getcwd(), \"tsv\"))\n",
        "    if not os.path.exists(tsv_directory):\n",
        "        os.makedirs(tsv_directory)\n",
        "\n",
        "    tsv_output_path = os.path.join(tsv_directory, f\"{image_name}.tsv\")\n",
        "    tsv_output_path = os.path.normpath(tsv_output_path)\n",
        "\n",
        "    print(f\"Running Tesseract on image: {image_path}\")\n",
        "    print(f\"Saving TSV to: {tsv_output_path}\")\n",
        "    print(f\"Command: tesseract \\\"{image_path}\\\" \\\"{tsv_output_path}\\\" -l eng tsv\")\n",
        "\n",
        "\n",
        "    tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
        "    # error_code = os.system(f'\"{tesseract_cmd}\" \"{image_path}\" \"{tsv_output_path}\" -l eng tsv')\n",
        "    result = subprocess.run([tesseract_cmd, image_path, tsv_output_path, \"-l\", \"eng\", \"tsv\"], capture_output=True, text=True)\n",
        "    \n",
        "\n",
        "    # if not error_code:\n",
        "    if result.returncode != 0:\n",
        "        print(f\"Error running Tesseract: {result.stderr}\")\n",
        "        raise ValueError(f\"Error running Tesseract on image {image_path}. Check Tesseract logs.\")\n",
        "    else:\n",
        "        print(f\"Tesseract completed successfully. Output: {result.stdout}\")\n",
        "        return tsv_output_path\n",
        "\n",
        "\n",
        "\n",
        "'''reads the file generated above, removes empty/missing entries,\n",
        "iterates through the cleaned dataset and stores words and bbox coordinates'''\n",
        "def clean_tesseract_output(tsv_output_path):\n",
        "    ocr_df = pd.read_csv(tsv_output_path, sep='\\t')\n",
        "    ocr_df = ocr_df.dropna()\n",
        "    ocr_df = ocr_df.drop(ocr_df[ocr_df.text.str.strip() == ''].index)\n",
        "    # text_output = ' '.join(ocr_df.text.tolist())\n",
        "\n",
        "    words = []\n",
        "    for index, row in ocr_df.iterrows():\n",
        "      word = {}\n",
        "      origin_box = [row['left'], row['top'], row['left'] + row['width'], row['top']+row['height']]\n",
        "      word['word_text'] = row['text']\n",
        "      word['word_box'] = origin_box\n",
        "      words.append(word)\n",
        "\n",
        "    return words          #array of dicts that include bbox coords and words details\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "C5Xe2P9C2dAp",
        "outputId": "4cfc5bc9-d07c-4e15-8291-b3270f253dc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shaz13/real-world-documents-collections/docs-sm/invoice\n",
            "Valid image: 0000137486.jpg\n",
            "Full image path before calling fucntion: shaz13/real-world-documents-collections/docs-sm/invoice\\0000137486.jpg\n",
            "Image exists: shaz13/real-world-documents-collections/docs-sm/invoice\\0000137486.jpg\n",
            "IMAGE PATH C:\\Users\\annap\\Desktop\\Year3\\stats\\document-classification\\shaz13\\real-world-documents-collections\\docs-sm\\invoice\\0000137486.jpg\n",
            "image name after supposedly removing the .tsv 0000137486\n",
            "Image C:\\Users\\annap\\Desktop\\Year3\\stats\\document-classification\\shaz13\\real-world-documents-collections\\docs-sm\\invoice\\0000137486.jpg loaded successfully.\n",
            "Running Tesseract on image: C:\\Users\\annap\\Desktop\\Year3\\stats\\document-classification\\shaz13\\real-world-documents-collections\\docs-sm\\invoice\\0000137486.jpg\n",
            "Saving TSV to: c:\\Users\\annap\\Desktop\\Year3\\stats\\document-classification\\tsv\\0000137486\n",
            "Command: tesseract \"C:\\Users\\annap\\Desktop\\Year3\\stats\\document-classification\\shaz13\\real-world-documents-collections\\docs-sm\\invoice\\0000137486.jpg\" \"c:\\Users\\annap\\Desktop\\Year3\\stats\\document-classification\\tsv\\0000137486\" -l eng tsv\n",
            "Tesseract completed successfully. Output: \n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\annap\\\\Desktop\\\\Year3\\\\stats\\\\document-classification\\\\tsv\\\\0000137486'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[33], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImage does NOT exist: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 68\u001b[0m words,bboxes \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_tesseract_tsv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# invoice_data = extract_invoice_data(text)\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# invoice_data[\"File Name\"] = filename\u001b[39;00m\n\u001b[0;32m     71\u001b[0m invoice_data_list\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: filename,\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: words,\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m: bboxes,\n\u001b[0;32m     75\u001b[0m })\n",
            "Cell \u001b[1;32mIn[33], line 4\u001b[0m, in \u001b[0;36mextract_text_bboxes\u001b[1;34m(image_path, use_tesseract_tsv)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_tesseract_tsv:                     \u001b[38;5;66;03m#tesseract TSV\u001b[39;00m\n\u001b[0;32m      3\u001b[0m   tsv_path \u001b[38;5;241m=\u001b[39m run_tesseract_on_image(image_path)\n\u001b[1;32m----> 4\u001b[0m   words_boxes \u001b[38;5;241m=\u001b[39m \u001b[43mclean_tesseract_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m   words \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m words_boxes]\n\u001b[0;32m      6\u001b[0m   bboxes \u001b[38;5;241m=\u001b[39m [item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword_box\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m words_boxes]\n",
            "Cell \u001b[1;32mIn[32], line 53\u001b[0m, in \u001b[0;36mclean_tesseract_output\u001b[1;34m(tsv_output_path)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclean_tesseract_output\u001b[39m(tsv_output_path):\n\u001b[1;32m---> 53\u001b[0m     ocr_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtsv_output_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m     ocr_df \u001b[38;5;241m=\u001b[39m ocr_df\u001b[38;5;241m.\u001b[39mdropna()\n\u001b[0;32m     55\u001b[0m     ocr_df \u001b[38;5;241m=\u001b[39m ocr_df\u001b[38;5;241m.\u001b[39mdrop(ocr_df[ocr_df\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mindex)\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\annap\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\annap\\\\Desktop\\\\Year3\\\\stats\\\\document-classification\\\\tsv\\\\0000137486'"
          ]
        }
      ],
      "source": [
        "def extract_text_bboxes(image_path, use_tesseract_tsv=True):\n",
        "    if use_tesseract_tsv:                     #tesseract TSV\n",
        "      tsv_path = run_tesseract_on_image(image_path)\n",
        "      words_boxes = clean_tesseract_output(tsv_path)\n",
        "      words = [item['word_text'] for item in words_boxes]\n",
        "      bboxes = [item['word_box'] for item in words_boxes]\n",
        "\n",
        "    # else:                                     #pytesseract\n",
        "    #   img = cv2.imread(image_path)\n",
        "    #   gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    #   gray = cv2.GaussianBlur(gray, (5,5), 0)\n",
        "    #   _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    #   extracted_text = pytesseract.image_to_string(thresh)\n",
        "\n",
        "    #   data = pytesseract.image_to_data(thresh, output_type=pytesseract.Output.DICT)   #extracts words, bboxes\n",
        "\n",
        "    #   words, bboxes = [], []\n",
        "    #   h, w, _ = img.shape\n",
        "\n",
        "    #   for i in range(len(data[\"text\"])):\n",
        "    #     if data[\"text\"][i].strip():\n",
        "    #       words.append(data[\"text\"][i])\n",
        "    #       x,y,w,h = data[\"left\"][i], data[\"top\"][i], data[\"width\"][i], data[\"height\"][i]\n",
        "    #       bbox = [\n",
        "    #           int((x/w)*1000),\n",
        "    #           int((y/h)*1000),\n",
        "    #           int(((x + w)/w) * 1000),\n",
        "    #           int(((y + h)/h) *1000)]      #1000x1000  normalizes bboxes\n",
        "    #       bboxes.append(bbox)\n",
        "\n",
        "    return words, bboxes\n",
        "\n",
        "\n",
        "\n",
        "def clean_text(df):\n",
        "    # df = df.dropna()\n",
        "    df = df.explode(\"tokens\")\n",
        "    df = df[df[\"tokens\"].str.strip() != '']\n",
        "\n",
        "    # text_output = ' '.join(df.text.tolist())\n",
        "\n",
        "    words = []\n",
        "    for index, row in df.iterrows():\n",
        "        word = {}\n",
        "        origin_box = row['bboxes']\n",
        "        word['word_text'] = row['tokens']\n",
        "        word['word_box'] = origin_box\n",
        "        words.append(word)\n",
        "\n",
        "    return words\n",
        "\n",
        "\n",
        "\n",
        "#prepares for inference\n",
        "invoice_data_list = []\n",
        "print(invoice_path)\n",
        "\n",
        "for filename in os.listdir(invoice_path):\n",
        "    if filename.lower().endswith(('.jpg', '.jpeg',)):\n",
        "        print(f\"Valid image: {filename}\")\n",
        "        image_path = os.path.join(invoice_path, filename)\n",
        "        print(f\"Full image path before calling fucntion: {image_path}\")\n",
        "        if os.path.exists(image_path):\n",
        "            print(f\"Image exists: {image_path}\")\n",
        "        else:\n",
        "            print(f\"Image does NOT exist: {image_path}\")\n",
        "            \n",
        "        words,bboxes = extract_text_bboxes(image_path, use_tesseract_tsv=True)\n",
        "        # invoice_data = extract_invoice_data(text)\n",
        "        # invoice_data[\"File Name\"] = filename\n",
        "        invoice_data_list.append({\n",
        "            \"file_name\": filename,\n",
        "            \"tokens\": words,\n",
        "            \"bboxes\": bboxes,\n",
        "        })\n",
        "    else:\n",
        "        print(f\"Skipping non-image file: {filename}\")\n",
        "\n",
        "df = pd.DataFrame(invoice_data_list)\n",
        "# print(df)\n",
        "# print(df.columns)\n",
        "\n",
        "\n",
        "df = clean_text(df)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JMRlBDktE1E"
      },
      "source": [
        "LayoutMv3 needs textual and spatial information. So, we need the bounding boxes of where the text is positioned within the picture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m70NuIuvrghL"
      },
      "outputs": [],
      "source": [
        "processor = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n",
        "\n",
        "#convert into huggnig face dataset\n",
        "hf_dataset = Dataset.from_pandas(df)\n",
        "print(hf_dataset[0])   #check it worked\n",
        "\n",
        "\n",
        "#passes words/bboxes into the layoutmv3 processer\n",
        "def preprocess(example, img_path):\n",
        "  img = Image.open(image_path.convert(\"RBG\"))\n",
        "  encoding = processor(\n",
        "      images=img,\n",
        "      text=example[\"tokens\"],\n",
        "      boxes=example[\"bboxes\"],\n",
        "      truncation=True,\n",
        "      padding=\"max_length\"\n",
        "  )\n",
        "  return encoding\n",
        "\n",
        "\n",
        "dataset = hf_dataset.train_test_split(test_size=0.2)\n",
        "train_dataset = dataset[\"train\"]\n",
        "test_dataset = dataset[\"test\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0RYjn4iKhKI"
      },
      "source": [
        "# Invoice Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xs0S3ZKTKi5A"
      },
      "outputs": [],
      "source": [
        "# we will need to recreate this for all categories\n",
        "def extract_invoice_data(text):\n",
        "    data = {}\n",
        "\n",
        "    data[\"Invoice Number\"] = re.search(r'Invoice\\s*No[:#]?\\s*([\\w-]+)', text, re.IGNORECASE)\n",
        "    data[\"Invoice Date\"] = re.search(r'Invoice\\s*Date[:#]?\\s*([\\d{2}/\\d{2}/\\d{4}]+)', text, re.IGNORECASE)\n",
        "    data[\"Due Date\"] = re.search(r'Due\\s*Date[:#]?\\s*([\\d{2}/\\d{2}/\\d{4}]+)', text, re.IGNORECASE)\n",
        "    data[\"Issuer Name\"] = re.search(r'From[:#]?\\s*([A-Za-z\\s]+)', text, re.IGNORECASE)\n",
        "    data[\"Recipient Name\"] = re.search(r'To[:#]?\\s*([A-Za-z\\s]+)', text, re.IGNORECASE)\n",
        "    data[\"Total Amount\"] = re.search(r'Total\\s*Amount[:#]?\\s*([\\d,]+\\.?\\d{2})', text, re.IGNORECASE)\n",
        "\n",
        "    for key, value in data.items():\n",
        "        data[key] = value.group(1) if value else \"Not Found\"\n",
        "\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw1YbzEuKLAi"
      },
      "source": [
        "# LayoutMv3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XapN_qyKNaT"
      },
      "outputs": [],
      "source": [
        "#pretrained layoutmv3 model\n",
        "model = AutoModelForSequenceClassification(\"microsoft/layoutlmv3-base\", num_labels=4)\n",
        "\n",
        "train_args = TrainingArguments(output_dir=\"./layoutlmv3_results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=5,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=2,\n",
        "    logging_dir=\"./logs\"\n",
        "    )\n",
        "\n",
        "\n",
        "trainer= Trainer(\n",
        "    model=model,\n",
        "    args=train_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        "    )\n",
        "\n",
        "\n",
        "trainer.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iECvxFshMXZt"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
